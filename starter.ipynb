{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "'Python Interactive'",
      "language": "python",
      "name": "4402cbc7-7940-4466-9f0f-fec540acd575"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philxhuang/udacity-projects/blob/master/starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swtQeAwXp4L5",
        "colab_type": "text"
      },
      "source": [
        "# Starter: Basic Data Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQW30FsXp4L6",
        "colab_type": "text"
      },
      "source": [
        "All the source codes are provided by Udacity. The codes are also modified by me to facilitate learning so the codes below should be easier to understand than random OOP attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOU4Oi5Yp4L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwEuZvjFrTkx",
        "colab_type": "code",
        "outputId": "d02d50fa-08b5-409c-84ab-684e32d0136d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# use this to check your PyTorch version and GUP availability\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LLQjr8ep4L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "    \"\"\" Sigmoid activation function \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        x: torch.Tensor\n",
        "    \"\"\"\n",
        "    return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDeBs6P8p4L_",
        "colab_type": "code",
        "outputId": "ec95bd63-3b6e-4ff2-c7bb-92427a3c4c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(10) # Set the random seed so things are predictable\n",
        "\n",
        "# setting a seed has to do with how python generates pseudo \"random\" data, read more on your own\n",
        "\n",
        "# Features are 5 random normal variables\n",
        "features = torch.randn((1, 5)) # create [1,5] matrix/row vector\n",
        "print(features)\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(features) # create a matrix with the same (dimension)\n",
        "print(weights)\n",
        "# and a true bias term\n",
        "bias = torch.randn((1, 1)) # this is a [1,1] dot vector as bias\n",
        "print(bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6014, -1.0122, -0.3023, -1.2277,  0.9198]])\n",
            "tensor([[-0.3485, -0.8692, -0.9582, -1.1920,  1.9050]])\n",
            "tensor([[-0.9373]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP-6FrTmp4ME",
        "colab_type": "code",
        "outputId": "365cb04f-1838-4a4f-8f50-9da4f3ca6236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Now, make our labels from our data and true weights\n",
        "'''\n",
        "y = activation(torch.sum(features * weights) + bias)\n",
        "y = activation((features * weights).sum() + bias)\n",
        "'''\n",
        "# this is the most basic way to do it, but we can write cleaner code"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ny = activation(torch.sum(features * weights) + bias)\\ny = activation((features * weights).sum() + bias)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wtQEJqBp4MG",
        "colab_type": "code",
        "outputId": "00f4d3a7-47c6-413e-d522-c5183888f784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This is much cleane\n",
        "'''\n",
        "torch.mm() does not broadcast, only for 2-d\n",
        "torch.matmal() does broad cast, for higher demensions\n",
        "'''\n",
        "\n",
        "#                         [1,5]    *    [5,1]          [1]\n",
        "y = activation(torch.mm(features, weights.view(5,1)) + bias)\n",
        "print(\"one forward pass creates the inner/dot product at\", y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one forward pass creates the inner/dot product at tensor([[0.9748]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdQQRblip4MI",
        "colab_type": "text"
      },
      "source": [
        "What we just did is to create a super simple neural network with one weight matrix (1 layer) and pass all the weights for only once.\n",
        "\n",
        "Now let's create a network with 2 layers. Notice that layers will decrease over time because in **THIS PARTICULAR EXERCISE**, we want our input matrices to come out as an inner product."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oxensrUp4MJ",
        "colab_type": "code",
        "outputId": "999134ff-4c24-470a-c8bc-c3cb4b2654df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(10) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, 3)) # dimension [1,3]\n",
        "print('features: ', features)\n",
        "\n",
        "# Define the size of each layer in our network\n",
        "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
        "n_hidden = 2                    # Number of hidden units \n",
        "n_output = 1                    # Number of output units\n",
        "\n",
        "# Weights for inputs to hidden layer, [3,2]\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "print('W1: ', W1)\n",
        "# Weights for hidden layer to output layer, [2,1]\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "print('W2:', W2)\n",
        "\n",
        "# and bias terms for hidden and output layers, [1,# of columns]\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))\n",
        "print(B1, B2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features:  tensor([[-0.6014, -1.0122, -0.3023]])\n",
            "W1:  tensor([[-1.2277,  0.9198],\n",
            "        [-0.3485, -0.8692],\n",
            "        [-0.9582, -1.1920]])\n",
            "W2: tensor([[ 1.9050],\n",
            "        [-0.9373]])\n",
            "tensor([[-0.8465,  2.2678]]) tensor([[1.3615]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8IYnzgLp4MM",
        "colab_type": "code",
        "outputId": "c54171fb-daf4-4f99-b62a-128812e54539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Now pass through the matrix in order\n",
        "h = activation(torch.mm(features, W1) + B1)\n",
        "output = activation(torch.mm(h, W2) + B2)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8418]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ou8IG_Ep4MP",
        "colab_type": "text"
      },
      "source": [
        "# Bonus: Numpy-Torch Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CxgflWp4MQ",
        "colab_type": "code",
        "outputId": "65910013-6445-49b3-82b4-9291385bef48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.rand(4,3)\n",
        "print('a is a numpy array', a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a is a numpy array [[0.66043138 0.49387078 0.50198118]\n",
            " [0.14943039 0.66726578 0.46902102]\n",
            " [0.36100858 0.4058508  0.08473571]\n",
            " [0.14358369 0.77798556 0.06239596]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqtaGq8Mp4MT",
        "colab_type": "code",
        "outputId": "cde8074b-7ff6-4b10-e4d9-4178fd8e988e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "b = torch.from_numpy(a)\n",
        "print('b is a torch tensor object converted from numpy array', b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b is a torch tensor object converted from numpy array tensor([[0.6604, 0.4939, 0.5020],\n",
            "        [0.1494, 0.6673, 0.4690],\n",
            "        [0.3610, 0.4059, 0.0847],\n",
            "        [0.1436, 0.7780, 0.0624]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk0HQdIDp4MW",
        "colab_type": "code",
        "outputId": "de0dd3ae-a798-4496-ae96-ae99234759ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "c = b.numpy()\n",
        "print('c is a new variable, converted back to numpy array', c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c is a new variable, converted back to numpy array [[0.66043138 0.49387078 0.50198118]\n",
            " [0.14943039 0.66726578 0.46902102]\n",
            " [0.36100858 0.4058508  0.08473571]\n",
            " [0.14358369 0.77798556 0.06239596]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gannQqXcp4MZ",
        "colab_type": "code",
        "outputId": "b91ad5a3-ec4c-4adb-e801-7f5b5f01610e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Multiply PyTorch Tensor by 2, in place\n",
        "b.mul_(2)\n",
        "# Please know that this method is pretty old-fashioned.\n",
        "# For more, please go learn BROADCASTING."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3209, 0.9877, 1.0040],\n",
              "        [0.2989, 1.3345, 0.9380],\n",
              "        [0.7220, 0.8117, 0.1695],\n",
              "        [0.2872, 1.5560, 0.1248]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9SraSpFp4Mc",
        "colab_type": "code",
        "outputId": "ded2b6dd-c0a5-450a-eb70-cf1a2aa778e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "print(a)\n",
        "print(b, 'is the same as an alised a array')\n",
        "print(c)\n",
        "'''\n",
        "Unfortunately, the method torch.from_numpy shares the same memory.\n",
        "The best approch is use something like tensor(), not Tensor()\n",
        "Please do understand these subtle differences. Check out the documentation.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.32086275 0.98774156 1.00396236]\n",
            " [0.29886079 1.33453156 0.93804204]\n",
            " [0.72201715 0.81170161 0.16947142]\n",
            " [0.28716737 1.55597111 0.12479191]]\n",
            "tensor([[1.3209, 0.9877, 1.0040],\n",
            "        [0.2989, 1.3345, 0.9380],\n",
            "        [0.7220, 0.8117, 0.1695],\n",
            "        [0.2872, 1.5560, 0.1248]], dtype=torch.float64) is the same as an alised a array\n",
            "[[1.32086275 0.98774156 1.00396236]\n",
            " [0.29886079 1.33453156 0.93804204]\n",
            " [0.72201715 0.81170161 0.16947142]\n",
            " [0.28716737 1.55597111 0.12479191]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nUnfortunately, the method torch.from_numpy shares the same memory.\\nThe best approch is use something like tensor(), not Tensor()\\nPlease do understand these subtle differences. Check out the documentation.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzaM7Jg8p4Me",
        "colab_type": "text"
      },
      "source": [
        "End of Lession"
      ]
    }
  ]
}