{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-trainNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philxhuang/udacity-projects/blob/master/3_trainNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6mo1Cv2HOTh",
        "colab_type": "text"
      },
      "source": [
        "# Train NN with Back-Propagation and Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSWjGkWGHUb-",
        "colab_type": "code",
        "outputId": "426a1325-d9be-4ba6-d97d-11a79f96399a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8491412.12it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 130483.41it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2141912.16it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 48702.26it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM2rnBL7bTCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "   ''' Function for viewing an image and it's predicted classes.\n",
        "   '''\n",
        "   ps = ps.data.numpy().squeeze()\n",
        "\n",
        "   fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "   ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "   ax1.axis('off')\n",
        "   ax2.barh(np.arange(10), ps)\n",
        "   ax2.set_aspect(0.1)\n",
        "   ax2.set_yticks(np.arange(10))\n",
        "   if version == \"MNIST\":\n",
        "       ax2.set_yticklabels(np.arange(10))\n",
        "   elif version == \"Fashion\":\n",
        "       ax2.set_yticklabels(['T-shirt/top',\n",
        "                           'Trouser',\n",
        "                           'Pullover',\n",
        "                           'Dress',\n",
        "                           'Coat',\n",
        "                           'Sandal',\n",
        "                           'Shirt',\n",
        "                           'Sneaker',\n",
        "                           'Bag',\n",
        "                           'Ankle Boot'], size='small');\n",
        "   ax2.set_title('Class Probability')\n",
        "   ax2.set_xlim(0, 1.1)\n",
        "\n",
        "   plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViVTn1zeHUqs",
        "colab_type": "code",
        "outputId": "17a3b916-7a87-4651-f44e-b4dcdd12426e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                     )\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "print(images.shape)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3R8MA8lHxtV",
        "colab_type": "text"
      },
      "source": [
        "Now let's use Cross Entropy to calculate loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBQbdYw8HhLu",
        "colab_type": "code",
        "outputId": "6811cb6f-ea79-4c48-ca38-0fa6cbdbbd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss() # or nn.NLLLoss()\n",
        "\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3192, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IUhy28iH1hQ",
        "colab_type": "code",
        "outputId": "db640587-5760-46c6-8b53-f1e9c1a6461c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "# somehow loss already knows the nn you are using so you can magically call .backward()\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 0.0033,  0.0033,  0.0033,  ...,  0.0033,  0.0033,  0.0033],\n",
            "        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
            "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0032, -0.0032, -0.0032,  ..., -0.0032, -0.0032, -0.0032],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qazNkF8JBlt",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer for B-P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fcbsl9TIxtJ",
        "colab_type": "code",
        "outputId": "122376a1-ff2e-48fb-c5c7-430a55acfdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "print(optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.003\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjhXC39ZJGi0",
        "colab_type": "code",
        "outputId": "c0dd5997-ef9b-43d5-a732-9eb916dc651a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 1.9790e-02, -8.3396e-03, -1.6958e-02,  ..., -4.2878e-05,\n",
            "          2.3379e-02,  5.5667e-03],\n",
            "        [ 2.1647e-02,  2.7308e-03,  1.2207e-02,  ...,  2.9791e-02,\n",
            "          5.1376e-03,  2.3835e-02],\n",
            "        [ 2.2342e-02,  5.1012e-03, -4.2130e-03,  ..., -3.1117e-03,\n",
            "         -7.0995e-03, -2.5348e-02],\n",
            "        ...,\n",
            "        [ 1.4084e-02, -9.7710e-03,  6.0779e-03,  ...,  5.4476e-03,\n",
            "          1.2320e-02,  1.7704e-02],\n",
            "        [-2.4664e-02, -2.4701e-03, -2.8551e-02,  ...,  2.2403e-02,\n",
            "         -3.5173e-02,  2.1630e-02],\n",
            "        [ 8.5211e-03,  7.2085e-03, -7.3421e-03,  ...,  1.3559e-02,\n",
            "          6.0507e-03, -2.7050e-02]], requires_grad=True)\n",
            "Gradient - tensor([[-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
            "        [-0.0032, -0.0032, -0.0032,  ..., -0.0032, -0.0032, -0.0032],\n",
            "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH0TVn3WJMjV",
        "colab_type": "code",
        "outputId": "16b9849b-465e-433b-f9a3-97c6e96b7fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 1.9791e-02, -8.3382e-03, -1.6956e-02,  ..., -4.1455e-05,\n",
            "          2.3380e-02,  5.5681e-03],\n",
            "        [ 2.1657e-02,  2.7405e-03,  1.2217e-02,  ...,  2.9801e-02,\n",
            "          5.1472e-03,  2.3845e-02],\n",
            "        [ 2.2340e-02,  5.0992e-03, -4.2150e-03,  ..., -3.1137e-03,\n",
            "         -7.1015e-03, -2.5350e-02],\n",
            "        ...,\n",
            "        [ 1.4084e-02, -9.7710e-03,  6.0779e-03,  ...,  5.4476e-03,\n",
            "          1.2320e-02,  1.7704e-02],\n",
            "        [-2.4666e-02, -2.4717e-03, -2.8553e-02,  ...,  2.2401e-02,\n",
            "         -3.5174e-02,  2.1629e-02],\n",
            "        [ 8.5204e-03,  7.2078e-03, -7.3428e-03,  ...,  1.3559e-02,\n",
            "          6.0500e-03, -2.7051e-02]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfZDwnsDJ4CF",
        "colab_type": "text"
      },
      "source": [
        "Now let's run this many times, in epochs, to increase accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyGr-0lgJ9nE",
        "colab_type": "code",
        "outputId": "578a1b45-93d3-418f-debb-196cd52d4a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.8607617218865515\n",
            "Training loss: 0.8136474461253009\n",
            "Training loss: 0.5072553719221148\n",
            "Training loss: 0.4164863346355048\n",
            "Training loss: 0.37475872050915193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw0Bo9IGKJv_",
        "colab_type": "code",
        "outputId": "7ebf703c-c70e-4ae4-d323-ecb10a660ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}